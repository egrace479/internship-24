{"cells":[{"cell_type":"markdown","metadata":{"id":"c0C_MeUM22LS"},"source":["# Environment\n","\n","This course will be taught entirely in Google Colab. See an overview [here](https://colab.research.google.com). Note that Colab already has some popular packages installed (e.g., `torch`, `numpy`, `scikit-learn`, etc.); this just means that to run this code elsewhere you may need to install some of these packages first. \n","\n","Also, some images may not appear if you have third-party cookies disabled (applies to most Safari users) due to a Colab issue. This can be resolved by using another browser (e.g., Chrome), or you can download the notebook to see the images."]},{"cell_type":"markdown","metadata":{"id":"6ySiMJbaYG7D"},"source":["# Regression Example: California Housing Dataset\n","\n","[This dataset](https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html) is from the 1990 Census. The goal is to predict the median house value for households within one block (in hundreds of thousands of dollars). \n","\n","All variables refer to households within one block (Census blocks are the smallest geographical unit for which these data are available).\n","\n","## Dataset Description\n","\n","| Variable | Description |\n","|-------------|-------------|\n","| `MedInc`    | Median income for households (in tens of thousands of dollars) |\n","| `HouseAge`  | Median house age|\n","| `AveRooms`  | Average number of rooms per dwelling |\n","| `AveBedrms` | Average number of bedrooms per dwelling |\n","| `Population`| Number of people living in a block |\n","| `AveOccup`  | Average household occupancy |\n","| `Latitude`  | Block latitude |\n","| `Longitude` | Block longitude |\n","\n","## Libraries\n","\n","We will use [`pandas`](https://pandas.pydata.org) for data analysis and manipulation, [`scikit-learn`](https://scikit-learn.org/stable/index.html) for the models, and [`matplotlib`](https://matplotlib.org) for visualizations."]},{"cell_type":"markdown","metadata":{"id":"VMCIDL0qb_LW"},"source":["## Loading the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RMdVIfhE1oD_"},"outputs":[],"source":["import pandas as pd\n","from sklearn.datasets import fetch_california_housing\n","\n","# Load data\n","housing = fetch_california_housing()  # the scikit-learn library includes this dataset for educational/testing purposes\n","\n","# The basic object of the pandas library is the DataFrame, which is used to store tabular data\n","all_inputs = pd.DataFrame(housing.data, columns=housing.feature_names)  # pd.DataFrame used to create a DataFrame with the all the features \n","y = housing.target \n","\n","print('Response Variable:', housing.target_names)\n","print(y)\n","print('Input Variables:')\n","all_inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xuY_pXWLGVDK"},"outputs":[],"source":["# describe() is a method in the Pandas library\n","# It computes summary statistics for each column of a DataFrame\n","all_inputs.describe()"]},{"cell_type":"markdown","metadata":{"id":"fEgdZIuIjweX"},"source":["## Defining the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7kUUTLtxCaub"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Choose an input variable\n","X = all_inputs[['MedInc']] # Experiment with changing which variable we use as a predictor, do others work better?\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)  # 80%-20% train-test split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7hA9X0BCXAPC"},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","\n","# Create a single-variable linear regression model and fit it to the training data\n","reg = LinearRegression()\n","reg.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = reg.predict(X_test)\n","\n","# Calculate the mean squared error \n","mse = mean_squared_error(y_test, y_pred)\n","print(\"Mean squared error:\", mse)"]},{"cell_type":"markdown","metadata":{"id":"w-ot_lzwjnoV"},"source":["## Plotting our results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FByXC6vR689e"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Plot the data points\n","# s sets the point size, alpha sets the transparency\n","plt.scatter(X_test, y_test, s=15, color=\"tab:blue\", alpha=0.4)\n","\n","# Plot the regression line\n","y_pred = reg.predict(X_test)\n","plt.plot(X_test, y_pred, color=\"red\", linewidth=2)\n","\n","# Set plot title and axis labels\n","plt.title(\"Linear Regression\")\n","plt.xlabel(\"Median Income (tens of thousands of dollars)\")\n","plt.ylabel(\"Median House Value (hundreds of thousands of dollars)\")\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pwlxH2KL7lDK"},"outputs":[],"source":["from sklearn.metrics import PredictionErrorDisplay\n","\n","# Residual plot\n","# Generally, we don't want to see any pattern in the residual plot; such patterns indicate there is a systematic error in the model fit (i.e., the data are not well represented by a linear model)\n","# Here, there is a weird line pattern, but this just has to do with the Census capping the reported median house value at $500,000 (1990!)\n","\n","PredictionErrorDisplay.from_estimator(reg, X_test, y_test)  # scikit-learn has built-in methods to generate common visualizations\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MZ8ovMQB7pj3"},"outputs":[],"source":["# Residual Histogram\n","# We want to see that the residuals are approximately normally distributed\n","\n","residuals = y_test - y_pred\n","plt.hist(residuals, bins=20)\n","plt.xlabel(\"Residuals\")\n","plt.ylabel(\"Frequency\")\n","plt.title(\"Histogram of Residuals\")\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"U-vALUWN7AGg"},"source":["## Multivariable Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_K0Gv67G5ucg"},"outputs":[],"source":["X = all_inputs\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","\n","# Create a linear regression model with all of the variables\n","reg = LinearRegression()\n","reg.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = reg.predict(X_test)\n","\n","# Calculate the mean squared error\n","mse = mean_squared_error(y_test, y_pred)\n","print(\"Mean squared error:\", mse)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TTqrx82a1-pJ"},"outputs":[],"source":["# Residual plot\n","PredictionErrorDisplay.from_estimator(reg, X_test, y_test)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"20rFh0y7iGW2"},"outputs":[],"source":["# Residual Histogram\n","\n","residuals = y_test - y_pred\n","plt.hist(residuals, bins=20)\n","plt.xlabel(\"Residuals\")\n","plt.ylabel(\"Frequency\")\n","plt.title(\"Histogram of Residuals\")\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_0CouX2wCEVs"},"outputs":[],"source":["# Feature importance plot\n","# In a multivariable regression, we would like to know which predictors are contributing the most to our predicted value\n","# We can understand this by examining the coefficients of each predictor; a large coefficient (positive or negative) indicates that a change in the value of that predictor yields a large change in our prediction\n","# When interpreting the coefficients, it is important to know the scale of the variables. The coefficient of a variable measured in dollars will be larger than the coefficient of a variable measured in millions!\n","# This is one reason why feature normalization is often a good idea\n","\n","feature_importance = pd.Series(reg.coef_, index=X_train.columns)# pd.Series create a one-dimensional variables to present the coefficients of each predictable variable \n","feature_importance.plot(kind='barh')\n","plt.xlabel('Coefficient')\n","plt.title('Feature importance')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"pTqxE5UC3Ofc"},"source":["# Classification Example: Titanic Dataset\n","\n","This dataset is available for download [from Kaggle](https://www.kaggle.com/c/titanic/data). Note that the dataset loaded here is slightly different; it has been processed slightly.\n","\n","We are trying to predict whether a passenger survived the voyage using some basic information about them.\n","\n","\n","## Dataset Description\n","\n","| Variable | Description |\n","|-------------|----------|\n","| `Survived`    | Whether the passenger survived (0 = No, 1 = Yes)   |\n","| `Pclass`      | The class of the passenger's ticket (1 = 1st, 2 = 2nd, 3 = 3rd)   |\n","| `Sex`         | The passenger's sex  (0 = Female, 1 = Male) |\n","| `Age `        | The passenger's age (binned) |\n","| `Parch `      | The number of parents divided by the number of children the passenger had on board    |\n","| `Fare `       | The fare paid by the passenger   (binned)   |\n","| `Embarked`    | The port of embarkation (0 = Southampton, 1 = Cherbourg, 2 = Queenstown)                |\n","| `Name_length `       | Length of the passenger's name      |\n","| `Has_Cabin `      | If the cabin number is available     |\n","| `FamilySize`       | The number of people in the passenger's family unit     |\n","| `IsAlone`       | If the passenger travelled alone    |\n","| `Title`       | Term of address (1 = \"Mr.\", 2 = \"Miss.\", 3 = \"Mrs.\", 4 = \"Master.\", 5 = \"Don.\")     |\n"]},{"cell_type":"markdown","metadata":{"id":"QrU3ECkFfjKS"},"source":["## Loading the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NxBlegO13gRR"},"outputs":[],"source":["# Load the Titanic dataset\n","# pd.read_csv takes in a URL or filepath, and reads the contents into a DataFrame\n","titanic_df = pd.read_csv('https://raw.githubusercontent.com/wandb/examples/master/examples/scikit/scikit-titanic/train.csv')\n","\n","# Remove columns(axis=1) that are not useful for prediction, drop function to remove the PassengerId column \n","titanic_df = titanic_df.drop(['PassengerId'], axis=1)\n","\n","# Remove rows with missing data\n","titanic_df = titanic_df.dropna()\n","titanic_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yOpF1YZCIiAh"},"outputs":[],"source":["titanic_df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yug9ZWEs-q9i"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(titanic_df.drop('Survived', axis=1), \n","                                                    titanic_df['Survived'], \n","                                                    test_size=0.2, \n","                                                    random_state=42)  # the random_state argument sets a random seed, so this line will always produce the same split"]},{"cell_type":"markdown","metadata":{"id":"e4yor4wmfn1V"},"source":["## Model Selection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPRaucUE-pWy"},"outputs":[],"source":["from sklearn.svm import SVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import tree\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Choose which classifier you want to use, and uncomment the appropriate line\n","# Which performs the best on this dataset?\n","\n","classifier = SVC(kernel='linear')  # SVM\n","# classifier = LogisticRegression()\n","# classifier = tree.DecisionTreeClassifier()\n","# classifier = RandomForestClassifier(max_depth=2)\n","\n","\n","# You can also choose to alter the parameters of each classifier to see if you can achieve better performance\n","# SVMs can use different 'kernel' functions. Scikit-learn accepts the following values: 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'\n","# The scikit-learn documentation lists other parameters that are available to tweak; see if any of them help!\n","\n","# You can choose to set the random_state parameter if you want to be able to replicate results during your comparison"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6aEX7Hav3PiH"},"outputs":[],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Fit the model\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the testing set\n","y_pred = classifier.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","print('Accuracy:', accuracy)\n","print('Precision:', precision)\n","print('Recall:', recall)\n","print('F1 Score:', f1)"]},{"cell_type":"markdown","metadata":{"id":"GQPiqEPyf0u5"},"source":["## Evaluating the classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_PTOTj933i5T"},"outputs":[],"source":["from sklearn.metrics import ConfusionMatrixDisplay, PrecisionRecallDisplay, RocCurveDisplay\n","\n","# In this plot, the confusion matrix is displayed as follows:\n","#  --------------------------\n","# |            |             |\n","# |     TN     |      FP     |\n","# |            |             |\n","#  ---------------------------\n","# |            |             |\n","# |     FN     |      TP     |\n","# |            |             |\n","#  --------------------------\n","\n","ConfusionMatrixDisplay.from_estimator(classifier, X_test, y_test)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GFwaCeSHS0dr"},"outputs":[],"source":["PrecisionRecallDisplay.from_estimator(classifier, X_test, y_test)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBJjpfUi8hMV"},"outputs":[],"source":["# The ideal ROC curve hugs the upper left corner, and has AUC = 1\n","\n","RocCurveDisplay.from_estimator(classifier, X_test, y_test)\n","plt.show()"]}],"metadata":{"colab":{"provenance":[{"file_id":"1OSMw6EypxJHMk5_KzwBDWSTnxWyrK3uE","timestamp":1683858533235}],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
